\subsection{Future Directions}\label{subsec:future}\hypertarget{future}{}

\subsubsection{New Tests of Competing Models}
One attractive aspect of the EE modeling approach is that it opens the possibility of testing competing models of an aggregate outcome using patterns in the cross-section and panel dynamics of microeconomic expectations.  Since there are often many competing models that are able to fit aggregate patterns roughly equally well (stock price dynamics, say) it should be possible to winnow down the field of plausible contenders using their different predictions about microeconomic expectations data.\footnote{\cite{carroll2001epidemiology} provides one example, by showing that the time-series dynamics of micro-level \textit{disagreement} in inflation expectations matches reasonably well the predictions of his baseline SI model.  \cite{banerjee2013diffusion} provides another example.}

\subsubsection{New Kinds of Survey Data}
Common tools from epidemiological practice could usefully be imported into expectational surveys -- particularly tools that epidemiologists use to track the source of an infection (e.g., `contact tracing').  After a person's expectations have been elicited, at least a small amount of extra time should sometimes be allocated to asking ``why do you believe [x].''  In many cases the respondent might have a useful response: ``A friend told me'' or ``I read it in the newspaper'' or ``I did some research on the internet.''\footnote{\cite{arrondel2020informative} provide an example of this approach. They not only elicited survey respondents' stock market expectations, but also the size and financial expertise of the social circles within which they discuss financial matters. The paper finds that social interactions affect stock market beliefs mostly through information channels, instead of social  preferences.} %Any of these answers (or potentially others) might prove very helpful in narrowing the set of models that are plausible for explaining any particular set of beliefs.  %Direct questions could also help distinguish between different kinds of information: A job seeker might learn from friends that job prospects have improved, which causes improved expectations. These same friends might also tell the job-seeker about a specific current vacancy.  If job seekers were directly asked separate questions about expectations and vacancy tips, it would be much easier to distinguish a mechanism in which optimistic job-seekers work harder to find jobs from a mechanism in which job vacancy tips are more frequent in periods when optimism is greater.

Several times we have mentioned evidence that information from certain sources, or of some kinds, was more infectious;  other evidence indicated that certain recipients are more susceptible to infection.  %The literature on homophily, for example, suggests that ideas spread more readily among persons who have more in common.  And even among social connections with otherwise-similar characteristics, some are likely to be more credible than others.  %({\it ceteris paribus}, stock advice from an investment banker cousin might be more likely to be trusted than from his identical twin who is a circus acrobat.)
Direct survey questions asking respondents which sources of information they find most persuasive, and why, might prove very helpful in thinking about the most appropriate assumptions for our models.% (and potentially even addressing problems like Manski's reflection problem.)

\subsubsection{New and Big Data}
There is also a rapidly expanding body of work that tries to answer economic questions by analyzing `big data' on textual/conversational information using natural language processing (NLP).  (See \cite{gentzkow2019text} for an overview).  As those tools get more sophisticated, they might become usable for creating reliable methods for tracking the content of narratives in the manner required to turn Shiller's `narrative economics' ideas into practical tools of current analysis.

Separately, it is not beyond imagining that at some point, and to the extent that corporate interests and privacy considerations permit, it will be possible to train AI algorithms to comb through social network communications to identify economic narratives, and to measure the ways in which they spread.  Because such a source would have direct measures of social connections between agents, it might be possible to construct a thoroughly satisfactory epidemiological model of Shiller's narrative theory of economic fluctuations -- and to see how effective it is.  But that date is still some distance in the future.


%Epidemiological ideas might also prove to be useful in understanding how to interpret results like those in \cite{galesic2018asking}, who find that election surveys that ask participants about the voting intentions of their social contacts proved more accurate in predicting voting outcomes than surveys asking people how they themselves would vote, and other results that suggest that it is easier to elicit prevalence of socially stigmatized behaviors or attitudes by asking respondents about prevalence among members of their social circles rather than asking the respondent about themselves.  (``Are you a racist'' does not elicit useful responses - and may even result in the termination of the survey; ``how many of your friends would you say might be racist'' seems to generate much more revealing responses; cf \cite{radas2021predicted}.)